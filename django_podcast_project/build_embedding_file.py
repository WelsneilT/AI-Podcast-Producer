# build_embedding_file.py
import torch
import numpy as np
import os
import glob

def build_speaker_embedding_file():
    """
    ƒê·ªçc t·∫•t c·∫£ c√°c file x-vector .npy v√† gh√©p ch√∫ng th√†nh m·ªôt tensor duy nh·∫•t.
    """
    xvector_dir = "xvectors"
    output_file = "models/speaker_embeddings.pt"
    
    os.makedirs("models", exist_ok=True)
    
    if os.path.exists(output_file):
        print(f"‚úÖ File '{output_file}' ƒë√£ t·ªìn t·∫°i. Kh√¥ng c·∫ßn t·∫°o l·∫°i.")
        return

    npy_files = sorted(glob.glob(os.path.join(xvector_dir, "*.npy")))
    
    if not npy_files:
        print(f"üõë L·ªñI: Kh√¥ng t√¨m th·∫•y file .npy n√†o trong th∆∞ m·ª•c '{xvector_dir}'.")
        print("   Vui l√≤ng t·∫£i v√† gi·∫£i n√©n 'spkrec-xvect.zip' v√†o ƒë√≥.")
        return
        
    print(f"üîç T√¨m th·∫•y {len(npy_files)} file x-vector. ƒêang t·ªïng h·ª£p...")
    
    all_embeddings = []
    for f in npy_files:
        embedding = np.load(f)
        all_embeddings.append(torch.from_numpy(embedding))
        
    final_tensor = torch.stack(all_embeddings)
    
    torch.save(final_tensor, output_file)
    print("\nüéâ TH√ÄNH C√îNG! ƒê√£ t·∫°o v√† l∆∞u file speaker embeddings t·∫°i:")
    print(f"   -> {os.path.abspath(output_file)}")
    print(f"   Tensor c√≥ k√≠ch th∆∞·ªõc: {final_tensor.shape}")

if __name__ == "__main__":
    build_speaker_embedding_file()